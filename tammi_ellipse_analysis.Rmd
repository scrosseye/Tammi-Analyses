---
title: "TAMMI Analysis ELLIPSE content words"
author: "Crossley"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: yes
    number_sections: yes
---

This analysis was conducted using the ELLIPSE corpus available at https://github.com/scrosseye/ELLIPSE-Corpus.

The corpus was ran through the The Tool for Automatic Measurement of Morphological Information (TAMMI) available at linguisticanalysistools.org

  - Only the indices normed by content words were used.

Clean up environment and call in tidyverse

```{r}

rm(list=ls(all=TRUE))
library(tidyverse)

```

# Initial correlations 

These are for the entire dataset regardless of Multi-collinerity

Also, includes word count to assess correlations with text length 


```{r}

all_variables <- read_csv("tammi_ellipse.csv")
str(all_variables)

all_var_corr <- all_variables[, c(8:14, 5, 15:56)]
str(all_var_corr)

all_var_corr_matrix <- cor(all_var_corr)

write.csv(all_var_corr_matrix, "all_variables_corr_matrix_ellipese.csv")

```



# Wrangle data

Call in non-multicollinear variables and keep only those variables.

- These are only variables that are not multi-collinear with one another.

```{r}

list.files()
non_mc <- read_csv("multicollear_ellipse_overall.csv") #read non-collinear variables in
str(non_mc)

variables <- non_mc[, 1] #grab up variable names
str(variables)
print(variables) #still a tibble

#pull variables out of tibble into vector
variables_2 <- variables %>% 
  pull(...1)

variables_2

#call in final data frame
tammi_results_2 <- read_csv("tammi_ellipse.csv") %>% 
  dplyr::select(Filename, Overall, variables_2)

```

# Statistical Analyses

##Correlations

```{r}

str(tammi_results_2)

#need better names for the correlation plots and matrices

tammi_results_3 <- tammi_results_2 %>% 
  rename(Prof_score = Overall, 
         num_morph = num_morphemes_per_cw,
         derive_ttr = derivational_TTR_10,
         inflect_var = mean_subset_inflectional_variety_10,
         number_roots = number_roots_per_cw, 
         affix_fam_size = affix_family_size_per_cw,
         prefix_len = prefix_len_per_cw,
         root_freq_fam = perc_more_freq_words_morpho_family_root,
         affix_freq_fam = perc_more_freq_words_morpho_family_affix_per_cw,
         affix_len = affix_len_per_cw)



str(tammi_results_3)

#grab up data needed

data_analysis <- tammi_results_3[, c(2:11)]
str(data_analysis)

#simple correlation matrix

corr_matrix <- cor(data_analysis)
corr_matrix

#save to csv file

write.csv(corr_matrix, "corr_matrix_tammi_ellipse_final_variables.csv")

#prettier plot using corrplot

library(corrplot)

pdf("corr_plot_ellipse.pdf")

corr_plot <- corrplot(corr_matrix, 
         type="lower", #put color strength on bottom
         tl.pos = "ld", #Character or logical, position of text labels, 'ld'(default if type=='lower') means left and diagonal,
         tl.cex = 1, #Numeric, for the size of text label (variable names).
         method="color", 
         addCoef.col="black", 
         diag=FALSE,
         tl.col="black", #The color of text label.
         tl.srt=45, #Numeric, for text label string rotation in degrees, see text
         is.corr = FALSE,
         #order = "hclust", #order results by strength
         #col=gray.colors(100), #in case you want it in gray...
         number.digits = 2) #number of digits after decimal



#print(corr_plot)
dev.off()


library(PerformanceAnalytics) #for chart.Correlation

pdf("corr_chart_ellipse.pdf")
chart.Correlation(data_analysis, histogram = TRUE, method = "pearson")
dev.off()

```

## Machine learning model

```{r}

library(caret)
str(data_analysis)

set.seed(1234)

# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
#method = cross validation, number = ten times (10 fold cross-validation)

#the 10 fold CV stepwise model used
lm_cv10_step <- train(Prof_score ~ .,data = data_analysis,
                           #method = "leapForward", #stepwise selection
                           #method = "leapBackward", #stepwise selection
                           method = "leapSeq", #stepwise selection 
                           tuneGrid = data.frame(nvmax = 1:9), #using 1-18 predictor that we have
                           trControl = train.control)

#the model
summary(lm_cv10_step)
lm_cv10_step$results 
lm_cv10_step

#best tuned model
lm_cv10_step$bestTune  #says include 9...

#which variables were strong predictors
summary(lm_cv10_step$finalModel)

#co-efficients for model using all 3 variables
coef(lm_cv10_step$finalModel, 8)

#There are suppression effects

```

**Suppression effects**

Need to remove variables that demonstrate suppression effects

```{r}

data_analysis_2 <- data_analysis[, c(1:5, 7:9)]
str(data_analysis_2)

set.seed(1234)


#the 10 fold CV stepwise model used
lm_cv10_step <- train(Prof_score ~ .,data = data_analysis_2,
                           #method = "leapForward", #stepwise selection
                           #method = "leapBackward", #stepwise selection
                           method = "leapSeq", #stepwise selection 
                           tuneGrid = data.frame(nvmax = 1:7), #using 1-18 predictor that we have
                           trControl = train.control)

#the model
summary(lm_cv10_step)
lm_cv10_step$results 
lm_cv10_step

#best tuned model
lm_cv10_step$bestTune  #says include 4...

#which variables were strong predictors
summary(lm_cv10_step$finalModel)

#co-efficients for model using all 3 variables
coef(lm_cv10_step$finalModel, 4)

#no suppression effects

```

**Final model**

```{r}

#many non-significant variables here...

final_lm <- lm(Prof_score ~ num_morph + inflect_var + number_roots + derive_ttr, data = data_analysis_2)
summary(final_lm)


```

Check variable importance metrics

```{r}
library(relaimpo)#variable importance

metrics_w_types_all <- calc.relimp(final_lm)
metrics_w_types_all

calc.relimp(final_lm,type=c("lmg","last","first","pratt"),rela=TRUE)
#this reports percentage of importance by variable that adds up to 100

```

Check for multicollinearity using VIF values

```{r}

car::vif(final_lm) #VIF values for the regression to ensure no problems with multi-collinearity

```

Check for normal distributions of residuals

```{r}

plot(final_lm, which = 1) #residual plot

```


## Interpret final model

**ELL students that have more proficient writing...**

- Use more morphemes
- Use a greater variety of morphemes
- Produce a greater number of roots


